#!/usr/bin/env python
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import io
import re
from functools import reduce

# --- Streamlitãƒšãƒ¼ã‚¸ã®åˆæœŸè¨­å®š ---
st.set_page_config(page_title="æç›Šè¨ˆç®—æ›¸ãƒ‡ãƒ¼ã‚¿æ•´ç†ãƒ»åˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")


def create_summary_from_chunk(df_chunk):
    """
    å˜ä¸€ã®ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆDataFrameï¼‰ã‚’å—ã‘å–ã‚Šã€å†…éƒ¨ã®å…¨å¹´åº¦ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ãŸã¾ã¨ã‚è¡¨ã‚’ä½œæˆã™ã‚‹ã€‚
    """
    if df_chunk.empty:
        return None

    # --- 1. ãƒ–ãƒ­ãƒƒã‚¯å†…ã®å¹´åº¦ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã™ã¹ã¦æ¤œç´¢ ---
    year_pat = re.compile(r"^\s*20\d{2}\s*$")
    year_cells = []
    for r in range(df_chunk.shape[0]):
        for c in range(df_chunk.shape[1]):
            cell_value = df_chunk.iat[r, c]
            if pd.notna(cell_value) and bool(year_pat.match(str(cell_value))):
                year_cells.append({"row": r, "col": c, "year": int(str(cell_value).strip())})

    if not year_cells:
        return None

    year_cells.sort(key=lambda x: x['row'])
    
    unique_year_cells = []
    processed_years = set()
    for cell in year_cells:
        if cell['year'] not in processed_years:
            unique_year_cells.append(cell)
            processed_years.add(cell['year'])

    block_definitions = []
    for i, cell in enumerate(unique_year_cells):
        start_data_row = cell['row'] + 1
        # çµ‚äº†è¡Œã¯ã€æ¬¡ã®å¹´åº¦ã‚»ãƒ«ã®ç›´å‰ã‹ã€ãƒ–ãƒ­ãƒƒã‚¯ã®æœ€å¾Œã¾ã§
        end_data_row = unique_year_cells[i+1]['row'] if i + 1 < len(unique_year_cells) else len(df_chunk)
        block_definitions.append({
            "year": cell['year'], "col": cell['col'],
            "start": start_data_row, "end": end_data_row
        })

    # --- 2. å¹´åº¦ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€DataFrameã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ ---
    dfs = []
    for block in block_definitions:
        year = block['year']
        val_col = block['col']
        
        if 0 not in df_chunk.columns or val_col not in df_chunk.columns:
            continue
        
        sub = df_chunk.iloc[block['start']:block['end'], [0, val_col]].copy()
        sub.columns = ["å…±é€šé …ç›®", year]

        sub["å…±é€šé …ç›®"] = sub["å…±é€šé …ç›®"].astype(str).str.strip()
        sub.dropna(subset=["å…±é€šé …ç›®"], inplace=True)
        sub = sub[sub["å…±é€šé …ç›®"] != ""]
        if sub.empty: continue

        # ã€Œãã®ä»–ã€ã¯é‡è¤‡ã‚’è¨±å®¹ã—ã€ä»–ã¯å‰Šé™¤
        sonota_df = sub[sub["å…±é€šé …ç›®"] == "ãã®ä»–"].copy()
        other_items_df = sub[sub["å…±é€šé …ç›®"] != "ãã®ä»–"].copy()
        other_items_df.drop_duplicates(subset=["å…±é€šé …ç›®"], keep="first", inplace=True)
        sub = pd.concat([sonota_df, other_items_df]).sort_index()

        sub[year] = sub[year].replace({",": ""}, regex=True)
        sub[year] = pd.to_numeric(sub[year], errors="coerce").fillna(0)
        
        sub.set_index("å…±é€šé …ç›®", inplace=True)
        dfs.append(sub)

    if not dfs:
        return None

    # --- 3. å…¨å¹´åº¦ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦æ•´å½¢ ---
    consolidated = pd.concat(dfs, axis=1, join="outer").fillna(0)
    
    # å¹´åº¦åˆ—ã‚’æ˜‡é †ã«ã‚½ãƒ¼ãƒˆ
    year_cols = sorted([col for col in consolidated.columns if isinstance(col, (int, float))])
    consolidated = consolidated[year_cols]

    # é‡‘é¡ã‚’æ•´æ•°ã«å¤‰æ›
    for col in year_cols:
        consolidated[col] = consolidated[col].astype(int)

    consolidated.reset_index(inplace=True)
    return consolidated


def calculate_yoy(df):
    """å‰å¹´æ¯”ã¨å¢—æ¸›é¡ã‚’è¨ˆç®—ã™ã‚‹"""
    df_for_yoy = df.groupby("å…±é€šé …ç›®").sum().reset_index()
    df_yoy = df_for_yoy.set_index("å…±é€šé …ç›®")
    
    df_diff = df_yoy.diff(axis=1)
    df_diff.columns = [f"{col} å¢—æ¸›é¡" for col in df_diff.columns]
    
    df_pct = df_yoy.pct_change(axis=1) * 100
    df_pct.columns = [f"{col} å¢—æ¸›ç‡(%)" for col in df_pct.columns]

    df_merged = pd.concat([df_yoy, df_diff, df_pct], axis=1)
    
    sorted_cols = []
    year_cols = sorted([col for col in df_yoy.columns if isinstance(col, int)])
    for year in year_cols:
        sorted_cols.append(year)
        if f"{year} å¢—æ¸›é¡" in df_merged.columns:
            sorted_cols.append(f"{year} å¢—æ¸›é¡")
        if f"{year} å¢—æ¸›ç‡(%)" in df_merged.columns:
            sorted_cols.append(f"{year} å¢—æ¸›ç‡(%)")
            
    df_merged = df_merged[sorted_cols].reset_index()
    return df_merged


def process_file_by_page_delimiter(excel_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€Œ--- ãƒšãƒ¼ã‚¸ã€ã§åˆ†å‰²ã—ã€ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«ã¾ã¨ã‚è¡¨ã‚’ä½œæˆã™ã‚‹ã€‚
    """
    try:
        xls = pd.ExcelFile(excel_file)
        sheet_name_to_read = "æŠ½å‡ºçµæœ" if "æŠ½å‡ºçµæœ" in xls.sheet_names else xls.sheet_names[0]
        df_full = pd.read_excel(xls, sheet_name=sheet_name_to_read, header=None)
        st.info(f"ã‚·ãƒ¼ãƒˆã€Œ{sheet_name_to_read}ã€ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™...")
    except Exception as e:
        st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

    # --- 1. ã€Œ--- ãƒšãƒ¼ã‚¸ã€ã‚’åŸºæº–ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰² ---
    df_full[0] = df_full[0].astype(str)
    # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’å«ã‚€è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    split_indices = df_full[df_full[0].str.contains(r'--- ãƒšãƒ¼ã‚¸', na=False)].index.tolist()

    data_chunks = []
    last_idx = 0
    for idx in split_indices:
        chunk = df_full.iloc[last_idx:idx]
        if not chunk.empty:
            data_chunks.append(chunk.reset_index(drop=True))
        last_idx = idx
    # æœ€å¾Œã®åŒºåˆ‡ã‚Šæ–‡å­—ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    final_chunk = df_full.iloc[last_idx:]
    if not final_chunk.empty:
        data_chunks.append(final_chunk.reset_index(drop=True))

    if not data_chunks:
        # åŒºåˆ‡ã‚ŠãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…¨ä½“ã‚’1ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦æ‰±ã†
        data_chunks.append(df_full)

    # --- 2. å„ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†ã—ã¦ã€ã¾ã¨ã‚è¡¨ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ ---
    summary_tables = []
    for chunk in data_chunks:
        summary_table = create_summary_from_chunk(chunk)
        if summary_table is not None and not summary_table.empty:
            summary_tables.append(summary_table)
            
    return summary_tables


# --- Streamlitã®UIéƒ¨åˆ† ---
st.title("ğŸ“Š æç›Šè¨ˆç®—æ›¸ ãƒ‡ãƒ¼ã‚¿æ•´ç†ãƒ„ãƒ¼ãƒ«ï¼ˆãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šå¯¾å¿œï¼‰")
st.write("""
`--- ãƒšãƒ¼ã‚¸` ã¨ã„ã†è¨˜è¼‰ã‚’åŒºåˆ‡ã‚Šã¨ã—ã¦ã€å„ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ãŸã€Œã¾ã¨ã‚è¡¨ã€ã‚’ãã‚Œãã‚Œä½œæˆã—ã¾ã™ã€‚
""")

uploaded_file = st.file_uploader("å‡¦ç†ã—ãŸã„Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

if uploaded_file:
    st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å: `{uploaded_file.name}`")

    if st.button("ã¾ã¨ã‚è¡¨ã‚’ä½œæˆ â–¶ï¸", type="primary"):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ãƒ»åˆ†æä¸­..."):
            all_summaries = process_file_by_page_delimiter(uploaded_file)

        if all_summaries:
            st.success(f"âœ… {len(all_summaries)}å€‹ã®ã¾ã¨ã‚è¡¨ãŒä½œæˆã•ã‚Œã¾ã—ãŸï¼")

            # --- ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ ---
            output_excel = io.BytesIO()
            with pd.ExcelWriter(output_excel, engine="xlsxwriter") as writer:
                for i, summary_df in enumerate(all_summaries):
                    summary_df.to_excel(writer, sheet_name=f"ã¾ã¨ã‚è¡¨_{i+1}", index=False)
            
            st.download_button(
                label="ğŸ“¥ å…¨ã¦ã®ã¾ã¨ã‚è¡¨ã‚’Excelã§ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output_excel.getvalue(),
                file_name=f"ã¾ã¨ã‚è¡¨_{uploaded_file.name}",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
            st.divider()

            # --- å„ã¾ã¨ã‚è¡¨ã‚’Expanderã§è¡¨ç¤º ---
            for i, summary_df in enumerate(all_summaries):
                with st.expander(f"â–¼ **ã¾ã¨ã‚è¡¨ {i+1}** ã®åˆ†æçµæœã‚’è¦‹ã‚‹"):
                    tab1, tab2, tab3 = st.tabs(["æ•´ç†å¾Œãƒ‡ãƒ¼ã‚¿", "ğŸ“ˆ æ¨ç§»ã‚°ãƒ©ãƒ•", "ğŸ†š å‰å¹´æ¯”ãƒ»å¢—æ¸›"])
                    
                    with tab1:
                        st.dataframe(summary_df)
                    
                    with tab2:
                        st.subheader("ä¸»è¦é …ç›®ã®å¹´åº¦æ¨ç§»ã‚°ãƒ©ãƒ•")
                        items = summary_df["å…±é€šé …ç›®"].unique()
                        default_items = [item for item in ["å£²ä¸Šé«˜", "å–¶æ¥­åˆ©ç›Š", "çµŒå¸¸åˆ©ç›Š", "å½“æœŸç´”åˆ©ç›Š"] if item in items]
                        selected_items = st.multiselect(
                            "ã‚°ãƒ©ãƒ•ã«è¡¨ç¤ºã™ã‚‹é …ç›®ã‚’é¸æŠ", options=items, default=default_items, key=f"chart_{i}"
                        )
                        if selected_items:
                            df_chart = summary_df[summary_df["å…±é€šé …ç›®"].isin(selected_items)].groupby("å…±é€šé …ç›®").sum().T
                            df_chart.index.name = "å¹´åº¦"
                            st.line_chart(df_chart)
                    
                    with tab3:
                        st.subheader("å‰å¹´æ¯”ãƒ»å¢—æ¸›é¡")
                        df_yoy_result = calculate_yoy(summary_df)
                        st.dataframe(df_yoy_result.style.format(precision=2, na_rep='-'))

        else:
            st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
else:
    st.warning("â˜ï¸ ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
